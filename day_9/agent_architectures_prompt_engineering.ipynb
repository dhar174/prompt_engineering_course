{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622e7b16",
   "metadata": {},
   "source": [
    "# Prompt Engineering Notebook: Agent Architectures\n",
    "*Google Colab–Compatible — Author: ChatGPT (o3) — Date: 2025-07-09*\n",
    "\n",
    "This interactive notebook introduces **agent architectures** for language‑model‑driven applications. It blends theory with hands‑on demos to help you design, implement, and critique agentic systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94cdb70",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "By the end of this notebook you will be able to:\n",
    "1. Describe the difference between **reactive**, **planning**, **memory‑augmented**, and **multi‑agent** architectures.\n",
    "2. Implement a minimal reflex LLM agent that interacts with a user.\n",
    "3. Extend an agent with tool use following the **ReAct** pattern.\n",
    "4. Add simple long‑term memory via vector search.\n",
    "5. Coordinate multiple specialized agents to solve a task.\n",
    "6. Identify common pitfalls and safety issues in agent design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb907a4",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run the next cell to install lightweight dependencies used in the examples. Feel free to skip it if you already have them installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install minimal dependencies\n",
    "!pip -q install langchain openai faiss-cpu python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234b67d",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "If you plan to call the OpenAI API, execute the following cell after replacing `YOUR_KEY_HERE` with your key. The demos will still work with the stubbed local model provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass, textwrap\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '') or getpass.getpass('OpenAI API Key (leave blank to skip): ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0ce90",
   "metadata": {},
   "source": [
    "## 1. Why Agent Architectures?\n",
    "LLMs excel at single‑turn tasks, but many real‑world applications require **iterative reasoning, tool use, and memory**. Agent architectures wrap an LLM inside a control loop that repeatedly:\n",
    "1. **Observes** the environment (context, state, user input).\n",
    "2. **Thinks** using the LLM to decide on an action.\n",
    "3. **Acts** by calling tools/APIs or replying.\n",
    "4. **Learns** by updating memory or state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0eee4b",
   "metadata": {},
   "source": [
    "### Common Agent Categories\n",
    "| Category | Key Idea | Typical Use Cases |\n",
    "|----------|---------|-------------------|\n",
    "| **Reactive** | Respond one step at a time based on current observation. | Chatbots, lightweight assistants |\n",
    "| **Tool‑Using (ReAct)** | Interleave reasoning (`Thought:`) and tool calls (`Action:`). | Web search, code execution |\n",
    "| **Planning** | Builds a multi‑step plan before acting. | Complex tasks, code generation, workflows |\n",
    "| **Memory‑Augmented** | Reads/Writes to long‑term memory vectors or databases. | Personal assistants, tutoring |\n",
    "| **Multi‑Agent** | Multiple specialized agents collaborate via messages. | Research agents, software engineering |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386afae",
   "metadata": {},
   "source": [
    "### The Core Agent Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7431e00b",
   "metadata": {},
   "source": [
    "```python\n",
    "while not task_complete:\n",
    "    observation = observe()\n",
    "    thought     = think_with_llm(observation)\n",
    "    action      = interpret(thought)\n",
    "    result      = act(action)\n",
    "    learn_from(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b321d",
   "metadata": {},
   "source": [
    "## 2. Hands‑On: Building a Minimal Reflex Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class StubLLM:\n",
    "    \"\"\"A tiny fake 'LLM' that answers from a canned list so the notebook works offline.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.replies = [\n",
    "            \"Sure! What would you like me to do next?\",\n",
    "            \"I've done that. Anything else?\",\n",
    "            \"Task complete. 🎉\"\n",
    "        ]\n",
    "    def __call__(self, prompt):\n",
    "        return self.replies[random.randint(0, len(self.replies)-1)]\n",
    "\n",
    "class ReflexAgent:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    def chat(self, message):\n",
    "        prompt = f\"\"\"You are an assistant. Respond helpfully to: {message}\"\"\"\n",
    "        return self.llm(prompt)\n",
    "\n",
    "# Instantiate and test\n",
    "agent = ReflexAgent(StubLLM())\n",
    "for turn in range(3):\n",
    "    user_msg = input(f\"User ({turn+1}/3): \")\n",
    "    print(\"Agent:\", agent.chat(user_msg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c31e2",
   "metadata": {},
   "source": [
    "**Discussion:** This `ReflexAgent` illustrates the simplest architecture: input text → LLM → output text. There is no tool use, explicit memory, or planning.\n",
    "\n",
    "**Try it:** Rerun the cell, ask different questions, and observe the limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71978cd",
   "metadata": {},
   "source": [
    "## 3. Extending with Tool Use — ReAct Pattern\n",
    "The **ReAct** (Reason + Act) agent alternates between *Thought* and *Action* steps. Below is a minimal implementation that can perform arithmetic using a calculator tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57368f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "\n",
    "class CalculatorTool:\n",
    "    name = \"calculator\"\n",
    "    description = \"Evaluates basic math expressions like 2*3+1.\"\n",
    "    def __call__(self, expression: str):\n",
    "        try:\n",
    "            return str(eval(expression, {'__builtins__': {}}, math.__dict__))\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "\n",
    "class ReActAgent:\n",
    "    TOOL_PATTERN = re.compile(r\"Action: (\\w+)\\((.*)\\)\")\n",
    "    def __init__(self, llm, tools):\n",
    "        self.llm = llm\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "\n",
    "    def run(self, question, max_iters=4):\n",
    "        scratchpad = \"\"\n",
    "        for step in range(max_iters):\n",
    "            prompt = f\"\"\"Answer the question using the following tools when helpful.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "{scratchpad}\n",
    "\n",
    "Thought:\"\"\"\n",
    "            llm_output = self.llm(prompt)\n",
    "            scratchpad += f\"Thought: {llm_output}\\n\"\n",
    "            match = self.TOOL_PATTERN.search(llm_output)\n",
    "            if match:\n",
    "                tool_name, arg = match.group(1), match.group(2)\n",
    "                result = self.tools[tool_name](arg)\n",
    "                scratchpad += f\"Observation: {result}\\n\"\n",
    "            else:\n",
    "                return llm_output  # Final answer\n",
    "        return \"Failed to answer after max steps.\"\n",
    "\n",
    "# Demo with stub LLM that acts intentionally\n",
    "class MathLLM(StubLLM):\n",
    "    def __call__(self, prompt):\n",
    "        if \"Question:\" in prompt and \"sqrt(16)+4\" in prompt:\n",
    "            return \"Action: calculator(sqrt(16)+4)\"\n",
    "        return \"The answer is 8.\"\n",
    "react_agent = ReActAgent(MathLLM(), [CalculatorTool()])\n",
    "print(react_agent.run(\"What is sqrt(16)+4?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee701062",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "1. Modify `MathLLM` to answer a different math question.\n",
    "2. Replace `CalculatorTool` with a web search (hint: use `requests` to call DuckDuckGo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c2679",
   "metadata": {},
   "source": [
    "## 4. Planning Agents\n",
    "Planning agents create a structured sequence of steps *before* execution. They can optimize or verify the plan, improving reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ec3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_planner(goal: str):\n",
    "    \"\"\"Return a naïve three‑step plan as a list of strings.\"\"\"\n",
    "    return [f\"Step 1: Break down '{goal}'\", \n",
    "            \"Step 2: Do the thing\", \n",
    "            \"Step 3: Verify and summarize\"]\n",
    "\n",
    "print(simple_planner(\"Write a blog post about agent architectures\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07957c",
   "metadata": {},
   "source": [
    "**Challenge:** Implement a `PlannerAgent` that first calls `simple_planner`, then executes each step with an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d59402",
   "metadata": {},
   "source": [
    "## 5. Adding Long‑Term Memory\n",
    "Many tasks need context beyond the current turn. Vector databases like **FAISS** enable similarity search over past interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94060d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "\n",
    "# Build a toy memory of past notes\n",
    "notes = [\"Charles likes minimalism.\", \n",
    "         \"Charles teaches Prompt Engineering.\", \n",
    "         \"Charles lives in Michigan.\"]\n",
    "emb = OpenAIEmbeddings() if os.getenv('OPENAI_API_KEY') else None\n",
    "if emb:\n",
    "    store = FAISS.from_texts(notes, emb)\n",
    "    query = \"Where does Charles live?\"\n",
    "    docs = store.similarity_search(query)\n",
    "    print(\"Top memory match:\", docs[0].page_content)\n",
    "else:\n",
    "    print(\"⚠️ Skipping FAISS demo — set your API key to enable embeddings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642bcb4f",
   "metadata": {},
   "source": [
    "**Discussion:** Vector memory allows the agent to retrieve relevant past facts during reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213ff1b",
   "metadata": {},
   "source": [
    "## 6. Multi‑Agent Collaboration\n",
    "In complex domains, multiple specialized agents can message each other. Below, the **Coordinator** forwards a task to two sub‑agents and merges the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d858401",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    def __init__(self, agents):\n",
    "        self.agents = agents\n",
    "\n",
    "    def solve(self, problem):\n",
    "        results = [agent.chat(problem) for agent in self.agents]\n",
    "        return \"\\n---\\n\".join(results)\n",
    "\n",
    "team = Coordinator([ReflexAgent(StubLLM()), ReflexAgent(StubLLM())])\n",
    "print(team.solve(\"Draft two alternative replies to: 'Explain agent architectures.'\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1c5f7",
   "metadata": {},
   "source": [
    "**Activity:** Split into pairs and design two specialized agents (e.g., *Researcher* and *Writer*). Have them collaborate via the `Coordinator`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c4cd4",
   "metadata": {},
   "source": [
    "## 7. Safety & Evaluation Checklist\n",
    "- **Define boundaries:** Limit tool permissions (e.g., sandbox FS, rate‑limited APIs).\n",
    "- **Test‑driven prompts:** Write unit tests for critical tasks.\n",
    "- **Guardrails:** Validate tool arguments before execution.\n",
    "- **Logging & replay:** Store all agent traces for offline analysis.\n",
    "- **Red‑teaming:** Challenge the agent with adversarial prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389e027",
   "metadata": {},
   "source": [
    "## Further Reading & Resources\n",
    "- Yao et al., *ReAct: Synergizing Reasoning and Acting in Language Models* (2023)\n",
    "- Shinn et al., *Reflexion: Language Agents with Verbal Reinforcement Learning* (2023)\n",
    "- OpenAI **Function Calling** & **Assistant API** docs\n",
    "- Microsoft *AutoGen* framework\n",
    "- LangChain Agents documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc81e9",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "1. Build an agent that reads a TODO list in a text file and marks completed tasks using tool calls.\n",
    "2. Evaluate it against at least **five** edge cases (invalid task names, ambiguous commands, etc.).\n",
    "3. Submit a short report describing the architecture, prompt design, and evaluation results."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
