{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a5dc9e",
   "metadata": {},
   "source": [
    "# üìù Personalized Prompt Engineering\n",
    "### Building Context‚ÄëAware, User‚ÄëSpecific LLM Interactions (Colab Notebook)\n",
    "\n",
    "**Author:** Prompt Engineering Course\n",
    "\n",
    "---\n",
    "### Learning goals\n",
    "1. Understand the rationale and psychology behind prompt personalization.\n",
    "2. Explore common personalization patterns (slot‚Äëfilling, persona injection, memory‚Äëbased, etc.).\n",
    "3. Build data structures & retrieval pipelines that adapt prompts to individual users.\n",
    "4. Evaluate personalization quality & mitigate privacy / bias risks.\n",
    "5. Practice hands‚Äëon with OpenAI (or compatible) APIs in Colab.\n",
    "\n",
    "Run every code cell (‚åò/Ctrl‚ÄØ+‚ÄØEnter) in order. Feel free to modify & explore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e089e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ‚öôÔ∏è Install & import dependencies\n",
    "!pip -q install --upgrade openai faiss-cpu sentence-transformers\n",
    "\n",
    "import os, json, time, random\n",
    "from typing import Dict, List\n",
    "import openai, faiss\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "#@markdown **‚¨ÖÔ∏è Paste your OpenAI API key and run**\n",
    "openai.api_key = \"sk-...\"  # ‚Üê¬†replace with your key\n",
    "MODEL = \"gpt-4o-mini\"   # or any chat‚Äëcompletion model\n",
    "\n",
    "print('Ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5073056",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Why Personalize Prompts?\n",
    "- **Cognitive fit** ‚Äì users process information better when language, domain, and examples match their background.\n",
    "- **Trust & engagement** ‚Äì personalized tone increases perceived helpfulness.\n",
    "- **Task efficiency** ‚Äì fewer clarifications, higher first‚Äëtry success.\n",
    "- **LLM alignment** ‚Äì providing user data reduces hallucination via richer context.\n",
    "\n",
    "> *‚ÄúPersonalization turns a generic assistant into **my** assistant.‚Äù*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbf656",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ User & Context Modelling\n",
    "A minimal profile can be a Python dict or a row in a database. Key facets:\n",
    "1. **Demographics** ‚Äì language, locale, expertise.\n",
    "2. **Preferences** ‚Äì tone, output format, depth.\n",
    "3. **History** ‚Äì previous questions, documents, feedback.\n",
    "4. **Persona facts** ‚Äì name, pronouns, role.\n",
    "\n",
    "We'll start with an in‚Äëmemory toy profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy profile (expand as needed)\n",
    "user_profile = {\n",
    "    \"id\": \"u123\",\n",
    "    \"name\": \"Alex\",\n",
    "    \"role\": \"Data Analyst\",\n",
    "    \"preferred_tone\": \"concise\",\n",
    "    \"interests\": [\"sports analytics\", \"python\", \"coffee\"],\n",
    "    \"history\": []\n",
    "}\n",
    "print(json.dumps(user_profile, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b0dfc",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Personalization Patterns\n",
    "### 3.1 Slot‚ÄëFilling Templates\n",
    "Insert variables into a prompt string.\n",
    "```python\n",
    "template = \"Hey {name}! Here's a {tone} overview of {topic}.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeacefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üîß Slot‚ÄëFilling Demo\n",
    "def slot_prompt(profile:Dict, topic:str):\n",
    "    return (\n",
    "        f\"Hey {profile['name']}! \"\n",
    "        f\"Here's a {profile['preferred_tone']} overview of {topic}.\"\n",
    "    )\n",
    "\n",
    "prompt = slot_prompt(user_profile, \"vector databases\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77ebc6",
   "metadata": {},
   "source": [
    "### 3.2 Persona/Role Injection\n",
    "Add a **system** message describing the user's persona so the LLM adapts style & content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ü§ñ Persona Injection\n",
    "def chat_completion(profile, user_question):\n",
    "    messages=[\n",
    "        {\"role\":\"system\",\"content\":(\n",
    "            f\"You are a helpful assistant responding to {profile['name']}, \"\n",
    "            f\"a {profile['role']}. Use a {profile['preferred_tone']} tone.\"\n",
    "        )},\n",
    "        {\"role\":\"user\",\"content\":user_question}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(chat_completion(user_profile, \"Explain FAISS in 2 sentences.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f497025",
   "metadata": {},
   "source": [
    "### 3.3 Memory‚ÄëBased Personalization\n",
    "Retrieve past interactions (or external documents) similar to the current query and prepend them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e343d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üìö Simple Memory Store with FAISS\n",
    "emb_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Build vector index of previous Q&A pairs\n",
    "dimension = emb_model.get_sentence_embedding_dimension()\n",
    "memory_index = faiss.IndexFlatL2(dimension)\n",
    "stored_texts: List[str] = []\n",
    "\n",
    "def add_memory(text:str):\n",
    "    vec = emb_model.encode([text])\n",
    "    memory_index.add(vec)\n",
    "    stored_texts.append(text)\n",
    "\n",
    "# Add a couple of memories\n",
    "add_memory('Alex likes quick bullet‚Äëpoints.')\n",
    "add_memory('Alex asked about cosine similarity last week.')\n",
    "\n",
    "def retrieve_memories(query:str, k=2):\n",
    "    vec = emb_model.encode([query])\n",
    "    D,I = memory_index.search(vec,k)\n",
    "    return [stored_texts[i] for i in I[0] if i<len(stored_texts)]\n",
    "\n",
    "print(retrieve_memories('similarity search'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ca89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üß† Memory‚ÄëAware Chat Helper\n",
    "def personalized_chat(profile, question):\n",
    "    memories = '\\n'.join(retrieve_memories(question, k=2))\n",
    "    system_msg = (\n",
    "        f\"You are chatting with {profile['name']} (a {profile['role']}). \"\n",
    "        f\"Tone: {profile['preferred_tone']}. Relevant memories:\\n{memories}\"\n",
    "    )\n",
    "    messages=[{\"role\":\"system\",\"content\":system_msg},\n",
    "              {\"role\":\"user\",\"content\":question}]\n",
    "    return openai.chat.completions.create(model=MODEL, messages=messages).choices[0].message.content\n",
    "\n",
    "print(personalized_chat(user_profile, 'Could you revisit cosine similarity briefly?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973cd84",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Evaluating Personalization Quality\n",
    "| Metric | Description |\n",
    "|---|---|\n",
    "| Relevance | Does the answer reflect user profile (tone, domain)? |\n",
    "| Task success | Did the user achieve their goal? |\n",
    "| Engagement | Click‚Äëthrough, follow‚Äëup rate. |\n",
    "| Preference score | Explicit thumbs‚Äëup/down or RLHF. |\n",
    "| Fairness & bias | No undue stereotyping or exclusion. |\n",
    "\n",
    "Below is a very lightweight automated check using embedding similarity between the prompt and the user profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ‚öñÔ∏è Simple Embedding Similarity Scorer\n",
    "def personalization_score(profile, response):\n",
    "    profile_text = ' '.join([profile['role']] + profile['interests'])\n",
    "    vec1, vec2 = emb_model.encode([profile_text, response])\n",
    "    score = util.cos_sim(vec1, vec2).item()\n",
    "    return score\n",
    "\n",
    "resp = personalized_chat(user_profile, 'Recommend a coffee playlist for coding.')\n",
    "print(resp)\n",
    "print('Personalization score (0‚Äë1 approx):', round(personalization_score(user_profile, resp), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee5b57",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Ethical & Privacy Considerations\n",
    "- **Data minimization**: store only what you need.\n",
    "- **Transparency**: tell users how their data is used.\n",
    "- **Opt‚Äëout**: allow disabling personalization.\n",
    "- **Bias mitigation**: watch for stereotypes introduced through profiling.\n",
    "- **Security**: encrypt PII at rest and in transit.\n",
    "\n",
    "Remember: *With great personalization comes great responsibility.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6d85d",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Hands‚ÄëOn Exercises\n",
    "1. **Template Builder** ‚Äì expand `slot_prompt` to support fallback defaults if profile keys are missing.\n",
    "2. **Multi‚ÄëUser Support** ‚Äì refactor the memory store to index by `profile['id']`.\n",
    "3. **RAG Personalization** ‚Äì connect FAISS to an external knowledge base (e.g., Markdown files) and condition answers on both user profile & retrieved docs.\n",
    "4. **A/B Test Prompt Tone** ‚Äì compare user satisfaction when `preferred_tone` is obeyed vs ignored.\n",
    "5. **Privacy Audit** ‚Äì list every place PII is stored in this notebook and propose mitigations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813cd280",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Further Reading & Resources\n",
    "- OpenAI docs: *Personalizing ChatGPT* (2024)\n",
    "- Liu et‚ÄØal., *Persona‚Äëbased Dialog Models* (ACL, 2021)\n",
    "- Google PAIR, *People + AI Guidebook* ‚Äì Personalization chapter\n",
    "- Blog: *Dynamic Prompt Engineering with User Embeddings* (2025)\n",
    "- GitHub: `p-e/prompt‚Äëpersonalization‚Äëtoolkit`\n",
    "\n",
    "---\n",
    "üèÅ **End of notebook** ‚Äì experiment, iterate & enjoy personalized prompts!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
