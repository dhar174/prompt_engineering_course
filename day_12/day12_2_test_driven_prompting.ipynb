{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be683f3",
   "metadata": {},
   "source": [
    "\n",
    "# Day 12 · Notebook 2 — Test‑Driven Prompting\n",
    "\n",
    "**Concept #82 & #83** — *Write the tests first; prompts will follow.*\n",
    "\n",
    "In traditional software, unit tests catch regressions early. We can do the same for prompts:\n",
    "\n",
    "1. Specify *expected intent & style* as assertions.  \n",
    "2. Run the prompt against the LLM with a fixed seed or low temperature.  \n",
    "3. Refactor until the test passes.  \n",
    "4. Keep the test in CI so future edits stay green.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install dependencies (comment out if already installed)\n",
    "# !pip install -q openai pytest tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2bf4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "cat > prompt_test_suite.py <<'PYTEST'\n",
    "import pytest, re, hashlib, os\n",
    "import openai\n",
    "\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")  # Make sure this is set in Colab!\n",
    "\n",
    "def run_prompt(prompt, **params):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=params.get(\"temperature\", 0),\n",
    "        max_tokens=128,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def test_greet_formally():\n",
    "    \"\"\"Prompt should always greet with 'Good' and end with exactly one exclamation mark.\"\"\"\n",
    "    result = run_prompt(\"You are a formal greeter. Say hello to Charles.\")\n",
    "    assert re.match(r\"Good.*!$\", result)\n",
    "\n",
    "def test_hash_stability():\n",
    "    \"\"\"The same prompt+params should have a stable SHA256 digest (deterministic seed).\"\"\"\n",
    "    result = run_prompt(\"Return the word TEST.\", temperature=0)\n",
    "    digest = hashlib.sha256(result.encode()).hexdigest()\n",
    "    # Update the expected digest after first green run\n",
    "    expected = \"UPDATE_ME\"\n",
    "    assert digest == expected\n",
    "PYTEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56626a",
   "metadata": {},
   "source": [
    "\n",
    "### Red/Green Cycle\n",
    "\n",
    "1. Run `pytest -q prompt_test_suite.py`  \n",
    "2. Observe failures (“red”)  \n",
    "3. Modify the prompts or parameters until all tests pass (“green”).  \n",
    "4. Commit both prompt and tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051b72e",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise:** Replace `UPDATE_ME` with the actual digest after your first successful run, then re‑run the suite to go green.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day12_2_test_driven_prompting.ipynb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
