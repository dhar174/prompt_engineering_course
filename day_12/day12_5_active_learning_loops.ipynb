{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f0abdf",
   "metadata": {},
   "source": [
    "\n",
    "# Day‚ÄØ12 ¬∑ Notebook‚ÄØ5 ‚Äî Active‚ÄëLearning & Prompt¬†Retraining  (Concepts‚ÄØ#106¬†&¬†#151)\n",
    "\n",
    "We‚Äôll capture real‚Äëtime **thumbs‚Äëup / thumbs‚Äëdown** feedback, store it in SQLite, and periodically fine‚Äëtune or choose better prompt variants.\n",
    "\n",
    "*DeepSeek¬†R1* shows how a modest *Process‚ÄëReward Model* (PRM) can steer generation quality without full RLHF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3, datetime, json, openai, os, random\n",
    "\n",
    "conn = sqlite3.connect(\"feedback.db\")\n",
    "conn.execute(\"\"\"CREATE TABLE IF NOT EXISTS feedback (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    prompt TEXT,\n",
    "    response TEXT,\n",
    "    rating INTEGER,\n",
    "    ts DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    ")\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "PROMPT = \"Explain photosynthesis to a 10‚Äëyear‚Äëold in exactly three sentences.\"\n",
    "\n",
    "def get_response(prompt=PROMPT):\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=100,\n",
    "    ).choices[0].message.content.strip()\n",
    "    return res\n",
    "\n",
    "# Simulated user rating (1üëç, 0üëé)\n",
    "def simulate_rating() -> int:\n",
    "    return random.choice([0,1])\n",
    "\n",
    "resp = get_response()\n",
    "rating = simulate_rating()\n",
    "conn.execute(\"INSERT INTO feedback(prompt,response,rating) VALUES(?,?,?)\",\n",
    "             (PROMPT, resp, rating))\n",
    "conn.commit()\n",
    "print(\"Stored feedback ‚Üí\", rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee59520",
   "metadata": {},
   "source": [
    "\n",
    "### Next Steps\n",
    "1. Aggregate feedback into a ‚Äúreplay buffer.‚Äù  \n",
    "2. Fine‚Äëtune a tiny reward model or simple heuristic scorer.  \n",
    "3. Use the scorer inside a *process‚Äësupervised* loop (√†‚ÄØla DeepSeek R1) to choose between multiple candidate generations.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day12_5_active_learning_loops.ipynb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
