{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfdf5f7",
   "metadata": {},
   "source": [
    "\n",
    "# **GraphRAG: Graph‑based Retrieval‑Augmented Generation**  \n",
    "*A practical, hands‑on tutorial for Prompt Engineering students*  \n",
    "\n",
    "---  \n",
    "**Learning Objectives**  \n",
    "1. Explain the motivation, benefits, and architecture of GraphRAG.  \n",
    "2. Build a small knowledge graph from unstructured documents.  \n",
    "3. Combine vector and graph retrieval for multi‑hop question answering.  \n",
    "4. Deploy & evaluate a reusable GraphRAG pipeline with LlamaIndex.  \n",
    "5. Explore advanced patterns (Neo4j, LangChain Graph flow, custom retrievers).  \n",
    "\n",
    "> **Prerequisites:** Basic Python & Colab familiarity, an OpenAI API key (or other chat‑completion endpoint) set as an environment variable (`OPENAI_API_KEY`).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e8ea5",
   "metadata": {},
   "source": [
    "\n",
    "## **Table of Contents**\n",
    "1. [Why GraphRAG?](#why)  \n",
    "2. [Setup & Dependencies](#setup)  \n",
    "3. [Build a Knowledge Graph](#build)  \n",
    "4. [Graph + Vector Retrieval Pipeline](#pipeline)  \n",
    "5. [Evaluation & Comparison](#eval)  \n",
    "6. [Advanced Topics (Neo4j, LangChain, Custom Retrievers)](#advanced)  \n",
    "7. [Exercises](#ex)  \n",
    "8. [References](#refs)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title ← Install core libraries (takes ~1 min)\n",
    "!pip -q install llama-index==0.11.40                 llama-index-graph-stores-neo4j                 llama-index-postprocessor-cohere-rerank                 neo4j networkx pyvis tiktoken openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232ec82",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"why\"></a>\n",
    "## 1 | Why GraphRAG?  \n",
    "\n",
    "Traditional **vector‑only RAG** treats each text chunk as an isolated embedding.  \n",
    "That works for topical similarity but struggles with:  \n",
    "\n",
    "* **Multi‑hop reasoning** (e.g. _\"Which director won an Oscar after collaborating with actor X?\"_)  \n",
    "* **Entity disambiguation** (multiple people named “Jordan”)  \n",
    "* **Explainability** (show paths between facts)  \n",
    "\n",
    "**Knowledge graphs** store **nodes** (entities/concepts) and **edges** (relationships).  \n",
    "By retrieving sub‑graphs that match a query, **GraphRAG** can:  \n",
    "\n",
    "* Provide *structured* context with explicit relations.  \n",
    "* Follow relationship paths for deeper answers.  \n",
    "* Reduce hallucinations by grounding in graph facts.  \n",
    "\n",
    "> **TL;DR:** GraphRAG = Vector Search ➕ Graph Traversal ➕ LLM Generation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eaad91",
   "metadata": {},
   "source": [
    "\n",
    "```text\n",
    "┌────────────┐       ┌───────────────┐\n",
    "│  Documents │──────▶│  Chunk & KG   │\n",
    "└────────────┘       │  Construction │\n",
    "                     └──────┬────────┘\n",
    "                            │ PropertyGraph\n",
    "                            ▼\n",
    "                    ┌──────────────────┐\n",
    " Query  ───────────▶│  Graph Retriever │\n",
    "                    └──────┬───────────┘\n",
    "                            │ nodes / paths\n",
    "                            ▼\n",
    "                    ┌──────────────────┐\n",
    " Query  ───────────▶│ Vector Retriever │\n",
    "                    └──────┬───────────┘\n",
    "                            │ chunks\n",
    "                            ▼\n",
    "                    ┌──────────────────┐\n",
    "                    │  Reranker /      │\n",
    "                    │  Context Builder │\n",
    "                    └──────┬───────────┘\n",
    "                            │ top‑k context\n",
    "                            ▼\n",
    "                    ┌──────────────────┐\n",
    "                    │   LLM (Generate) │\n",
    "                    └──────────────────┘\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ade515",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"setup\"></a>\n",
    "## 2 | Setup: Tiny Demo Corpus  \n",
    "\n",
    "We’ll create a **toy corpus** about movies & directors to keep runtime low but still illustrate multi‑hop reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a18a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "docs = SimpleDirectoryReader(input_files=[], input_texts=[\n",
    "    \"\"\"Christopher Nolan directed *Inception* (2010) and *Oppenheimer* (2023).\n",
    "    *Inception* stars Leonardo DiCaprio and was distributed by Warner Bros.\n",
    "    *Oppenheimer* features Cillian Murphy and explores the life of J. Robert Oppenheimer.\"\"\",\n",
    "\n",
    "    \"\"\"Greta Gerwig directed *Lady Bird* (2017) and *Barbie* (2023).\n",
    "    *Barbie* stars Margot Robbie and Ryan Gosling and made \\$1.4 billion worldwide.\n",
    "    *Lady Bird* stars Saoirse Ronan and was produced by A24.\"\"\",\n",
    "\n",
    "    \"\"\"Quentin Tarantino collaborated with Leonardo DiCaprio on *Django Unchained* (2012) and *Once Upon a Time in Hollywood* (2019).\n",
    "    Tarantino is known for nonlinear storylines and stylized violence.\"\"\"])\n",
    "print(f\"Loaded {len(docs)} documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ab03b3",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"build\"></a>\n",
    "### 2.1 | Construct a Knowledge Graph  \n",
    "\n",
    "We use LlamaIndex’s **`SimpleKGIndex`** to extract entities & relations via the LLM and populate an in‑memory property graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index import SimpleKGIndex, StorageContext, ServiceContext, KnowledgeGraphIndex\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.schema import EntityRelationship\n",
    "\n",
    "# Use your own model/provider; here we assume gpt‑4o‑mini\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "kg_index = SimpleKGIndex.from_documents(\n",
    "    docs,\n",
    "    llm=llm,\n",
    "    max_triplets_per_chunk=8,  # keep it small\n",
    ")\n",
    "print(\"KG contains\", len(kg_index.get_entity_nodes()), \"entities.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ad7e2",
   "metadata": {},
   "source": [
    "\n",
    "#### Visualise the Graph (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "g_nx = kg_index.get_networkx_graph()\n",
    "net = Network(height='400px', width='600px', notebook=True)\n",
    "net.from_nx(g_nx)\n",
    "net.show('graph.html')\n",
    "print(\"Interactive graph saved to graph.html (opens in Colab preview).\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5eaac7",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"pipeline\"></a>\n",
    "## 3 | Graph + Vector Retrieval Pipeline  \n",
    "\n",
    "LlamaIndex provides **`KnowledgeGraphRAGRetriever`** which  \n",
    "1. extracts entities from the query,  \n",
    "2. expands a sub‑graph (default depth = 2),  \n",
    "3. converts nodes & edges into context,  \n",
    "4. optionally merges with vector‑similar chunks.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(docs, service_context=ServiceContext.from_defaults(llm=llm))\n",
    "\n",
    "retriever = KnowledgeGraphRAGRetriever(\n",
    "    graph_store=kg_index.get_graph_store(),\n",
    "    vector_index=vector_index,\n",
    "    depth=2,\n",
    "    mode=\"hybrid\",           # graph + vector\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "qa_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=retriever,\n",
    "    llm=llm,\n",
    "    response_mode=\"compact\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcceddd2",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 | Run Example Queries  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d038ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "queries = [\n",
    "    \"Which films has Leonardo DiCaprio appeared in that were directed by Christopher Nolan?\",  # multi‑hop\n",
    "    \"How much money did the Greta Gerwig film starring Margot Robbie gross worldwide?\",        # attribute lookup\n",
    "]\n",
    "for q in queries:\n",
    "    print(\"\\n\\033[1mQ:\", q, \"\\033[0m\")\n",
    "    print(qa_engine.query(q))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc52c9",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"eval\"></a>\n",
    "## 4 | Quick Evaluation  \n",
    "\n",
    "Below we compare answers using **vector‑only retrieval** vs **GraphRAG** for a multi‑hop question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_qa = vector_index.as_query_engine(response_mode=\"compact\", llm=llm)\n",
    "question = \"Which actor worked with BOTH Greta Gerwig and Quentin Tarantino?\"\n",
    "print(\"\\nVector‑only answer →\", baseline_qa.query(question))\n",
    "print(\"\\nGraphRAG answer   →\", qa_engine.query(question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c6f37",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"advanced\"></a>\n",
    "## 5 | Advanced Topics  \n",
    "\n",
    "* **Neo4j backend:** Swap the in‑memory store with a full Neo4j instance (`Neo4jGraphStore`). See commented code below.  \n",
    "* **LangChain Graph flow:** Use `langchain-neo4j` + `LangGraph` for stateful multi‑step pipelines.  \n",
    "* **Custom retriever:** Combine text‑to‑Cypher generation, path‑aware ranking, or GNN‑based link prediction.  \n",
    "* **Reranking:** Add `CohereRerank` or `OpenAIEmbeddingReranker` post‑processors.  \n",
    "* **Scaling tips:** Pre‑compute entity links, limit graph expansion depth, cache Cypher queries, async calls.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OPTIONAL: connect to Neo4j\n",
    "# from llama_index.graph_stores import Neo4jGraphStore\n",
    "# neo4j_store = Neo4jGraphStore(\n",
    "#     username=\"neo4j\",\n",
    "#     password=\"<password>\",\n",
    "#     url=\"bolt://<host>:7687\",\n",
    "# )\n",
    "# kg_index_neo = SimpleKGIndex.from_documents(\n",
    "#     docs,\n",
    "#     graph_store=neo4j_store,\n",
    "#     llm=llm,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2680f7d",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"ex\"></a>\n",
    "## 6 | Exercises  \n",
    "\n",
    "1. **Entity‑linking tweak:** Modify the `max_triplets_per_chunk` and observe graph density.  \n",
    "2. **Domain shift:** Replace the toy corpus with your own class materials; rebuild the pipeline.  \n",
    "3. **Prompt engineering:** Craft a system prompt that explains *why* the answer is correct using explicit graph paths.  \n",
    "4. **Evaluation:** Implement BLEU / NL‑based metrics or LLM‑grader to quantify answer accuracy vs ground truth.  \n",
    "5. **Neo4j Explore:** Spin up Neo4j Aura DB Free and visualize the imported graph in Neo4j Bloom.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188aff8",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"refs\"></a>\n",
    "## 7 | References  \n",
    "\n",
    "* Neo4j Blog — “Create a GraphRAG Workflow Using LangChain & LangGraph” (2024).  \n",
    "* LlamaIndex Docs — *GraphRAG v2 Cookbook* (2025).  \n",
    "* Neo4j — “What is GraphRAG?” (2024).  \n",
    "* LangChain‑Neo4j Partner Package Announcement (2025).  \n",
    "* Peng et al., *Graph Retrieval‑Augmented Generation: A Survey* (2024).  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
