{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a727fb",
   "metadata": {},
   "source": [
    "# Prompt Versioning & Failure Log  \n",
    "Track iterative prompt changes, record failures, and analyze robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc413fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pandas ipywidgets openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, openai, tiktoken, datetime, ipywidgets as w\n",
    "from IPython.display import display\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'sk-')\n",
    "\n",
    "LOG_PATH = 'prompt_fail_log.csv'\n",
    "try:\n",
    "    log_df = pd.read_csv(LOG_PATH)\n",
    "except FileNotFoundError:\n",
    "    log_df = pd.DataFrame(columns=[\n",
    "        'timestamp','prompt_id','version','prompt_text',\n",
    "        'decoding_cfg','expected_behavior','observed_behavior','token_count'])\n",
    "\n",
    "def save_log():\n",
    "    log_df.to_csv(LOG_PATH, index=False)\n",
    "\n",
    "prompt_id = w.Text(value='math_demo', description='Prompt ID:')\n",
    "version = w.IntText(value=1, description='Version:')\n",
    "prompt_text = w.Textarea(value='Provide a poetic summary of climate change.', description='Prompt:', layout=w.Layout(width=\"100%\", height=\"80px\"))\n",
    "expected = w.Textarea(value='Should output <50 words, poetic style.', description='Expected:', layout=w.Layout(width=\"100%\", height=\"60px\"))\n",
    "observed = w.Textarea(value='', description='Observed:', layout=w.Layout(width=\"100%\", height=\"60px\"))\n",
    "cfg_box = w.Textarea(value='temperature=0.7, top_p=0.95', description='Decoding cfg:', layout=w.Layout(width=\"100%\", height=\"40px\"))\n",
    "run_btn = w.Button(description='Run & Log')\n",
    "table_out = w.Output()\n",
    "\n",
    "def run_and_log(_):\n",
    "    global log_df\n",
    "    enc = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "    n_tok = len(enc.encode(prompt_text.value))\n",
    "    cfg = {}\n",
    "    for kv in cfg_box.value.split(','):\n",
    "        if '=' in kv:\n",
    "            k, v = kv.split('=',1)\n",
    "            cfg[k.strip()] = eval(v.strip())\n",
    "    try:\n",
    "        resp = openai.ChatCompletion.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=[{'role':'user','content': prompt_text.value}],\n",
    "            max_tokens=200,\n",
    "            **cfg\n",
    "        )\n",
    "        out_text = resp.choices[0].message.content.strip()\n",
    "        observed.value = out_text\n",
    "    except Exception as e:\n",
    "        observed.value = f'Error: {e}'\n",
    "        out_text = observed.value\n",
    "    new_row = {\n",
    "        'timestamp': datetime.datetime.utcnow().isoformat(),\n",
    "        'prompt_id': prompt_id.value,\n",
    "        'version': version.value,\n",
    "        'prompt_text': prompt_text.value,\n",
    "        'decoding_cfg': cfg,\n",
    "        'expected_behavior': expected.value,\n",
    "        'observed_behavior': out_text,\n",
    "        'token_count': n_tok\n",
    "    }\n",
    "    log_df = pd.concat([log_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    save_log()\n",
    "    with table_out:\n",
    "        table_out.clear_output()\n",
    "        display(log_df.tail())\n",
    "\n",
    "run_btn.on_click(run_and_log)\n",
    "display(w.VBox([prompt_id, version, prompt_text, expected, cfg_box, run_btn, observed, table_out]))\n",
    "print(\"Use this template to iterate, log failures, and track fixes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272364a0",
   "metadata": {},
   "source": [
    "### Tips  \n",
    "* Increment the **version** number with each change.  \n",
    "* Filter the CSV later to compute a **robustness score** (success rate).  \n",
    "* Store this file in Git for full history."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
