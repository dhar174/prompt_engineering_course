{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b218a475",
   "metadata": {},
   "source": [
    "# Lab 2 â€“ Multiâ€‘Agent Prompting & Frameworks\n",
    "Designing cooperating LLM agents with LangChain Agents & tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91802ae",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "1. Understand agent architectures (toolâ€‘use, memory, delegation).\n",
    "2. Build a twoâ€‘agent researcher / summarizer workflow.\n",
    "3. Compare AutoGPT, BabyAGI, and Semantic Kernel at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37243305",
   "metadata": {},
   "source": [
    "### 1.Â Agent Basics\n",
    "LangChain Agents choose appropriate **tools** based on user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os, getpass, requests, json, textwrap\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"ðŸ”‘ OpenAI API Key: \")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "tools = load_tools([\"serpapi\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "agent.run(\"Find the three latest papers on retrievalâ€‘augmented generation and summarize them in five bullets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b1b85",
   "metadata": {},
   "source": [
    "### 2.Â Building a Twoâ€‘Agent Team\n",
    "Below we split roles: *Researcher* fetches sources; *Critic* validates.\n",
    "We keep it lightweight using function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher(query):\n",
    "    return agent.run(query)\n",
    "\n",
    "def critic(text):\n",
    "    prompt = f\"Please factâ€‘check the following summary for accuracy and add citations if missing.\\n{text}\"\n",
    "    return llm([HumanMessage(content=prompt)]).content\n",
    "\n",
    "summary = researcher(\"Explain LangChain expression language\")\n",
    "print(\"Researcher summary:\\n\", summary)\n",
    "print(\"\\nCritic review:\\n\", critic(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bd5823",
   "metadata": {},
   "source": [
    "### 3.Â Miniâ€‘Project â€“ Plan Your Own Multiâ€‘Agent Workflow\n",
    "Use the template below to specify agents, roles, and interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf57a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = {\n",
    "    \"Agent A\": {\"role\": \"Planner\", \"prompt\": \"\"},\n",
    "    \"Agent B\": {\"role\": \"Executor\", \"prompt\": \"\"},\n",
    "}\n",
    "for name, cfg in agents.items():\n",
    "    print(f\"{name} â€” {cfg['role']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee9375",
   "metadata": {},
   "source": [
    "### 4.Â Framework Spotlights\n",
    "* **AutoGPT / BabyAGI**: goalâ€‘driven loops with persistence.\n",
    "* **Flowise**: visual node editor for LangChain graphs.\n",
    "* **Semantic Kernel**: Microsoftâ€‘backed SDK for planner/skills."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
