{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c6cb03",
   "metadata": {},
   "source": [
    "# AI & LLM Governance Primer  \n",
    "**Comprehensive Reference & Lab Notebook**  \n",
    "*Last updated: 2025-07-09*  \n",
    "\n",
    "---\n",
    "\n",
    "This Colab notebook is a **deepâ€‘dive resource** covering the **policies, standards, and practical tooling** that currently shape responsible AI and largeâ€‘languageâ€‘model (LLM) deployment (2025).\n",
    "\n",
    "It blends:\n",
    "\n",
    "* **Curated background reading** (with links & citations)\n",
    "* **Handsâ€‘on code cells**: checklists, PDF parsing, compliance templates, automated policy lookups\n",
    "* **Interactive exercises** so learners can apply governance concepts to their own AI projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04068af7",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Objectives\n",
    "By the end, you should be able to:\n",
    "\n",
    "1. **Describe** major AI governance instruments (EU AIÂ Act, NISTâ€¯AIÂ RMF, ISOâ€¯42001, U.S. Executive orders, UKÂ AIÂ SafetyÂ Institute, OECD & UNESCO principles).  \n",
    "2. **Map** LLM useâ€‘cases to risk tiers and compliance obligations.  \n",
    "3. **Generate** a lightweight *System Card* and *Model Card* using structured prompts.  \n",
    "4. **Automate** governance tasks: parse policy PDFs, track regulatory updates, run checklists.  \n",
    "5. **Critically discuss** gaps, emerging trends, and open questions in frontier model oversight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150339b",
   "metadata": {},
   "source": [
    "## ðŸŒ 1. Global Policy Landscape (2024â€‘2025)\n",
    "\n",
    "| Region / Org | Instrument | Status | Key Features |\n",
    "|--------------|------------|--------|--------------|\n",
    "| **EU** | **AI Act** (Regulation (EU)Â 2024/1112) | Final text adoptedÂ 2024; enforcement startsÂ Augâ€¯2025 (phased) | Riskâ€‘based tiers (unacceptable â‡¢ minimal), GPAI obligations, transparency, fundamentalâ€‘rights impact assessment |\n",
    "| **USA (Federal)** | **Executive Orderâ€¯14110** (Safe, Secure & Trustworthy AI) + **OMB Mâ€‘24â€‘10** memorandum | In force (2023â€‘2024) | Agency risk management, redâ€‘team sharing, NIST testing, watermarking R&D |\n",
    "| **USA (NIST)** | **AI Risk Management FrameworkÂ 1.0** | Voluntary (Janâ€¯2023) | *Govern â€“ Map â€“ Measure â€“ Manage* core functions; profiles & playbooks |\n",
    "| **ISO/IEC** | **42001:2023â€¯AIMS** | Published Decâ€¯2023 | Managementâ€‘system standard akin to ISOâ€¯27001 but for AI governance |\n",
    "| **UK** | **AI Safety Institute** evaluations + *International AI SafetyÂ Reportâ€¯2025* | Ongoing | Frontierâ€‘model testing protocols, redâ€‘team hubs |\n",
    "| **OECD / UNESCO** | **OECD AI Principles (2019)**, **UNESCO Recommendation (2021)** | Soft law | Humanâ€‘centered, accountability, transparency, sustainable society |\n",
    "\n",
    "> ðŸ“Œ **Why multiple layers?** Regulations set *obligations*, standards provide *how*, frameworks guide *process*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696f4e0",
   "metadata": {},
   "source": [
    "## ðŸ”Ž 2. Mapâ€‘Yourâ€‘Useâ€‘Case to Risk Tiers  \n",
    "\n",
    "Run the cell below to input a short description of an AI application and receive:\n",
    "\n",
    "* EUÂ AIÂ Act tier suggestion  \n",
    "* Recommended NISTÂ AI RMF controls  \n",
    "* Flagged ISOâ€¯42001 clauses  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7394823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, textwrap\n",
    "description = \"Chatbot doctor that gives medical diagnosis to patients online\"\n",
    "print(\"Useâ€‘case:\", description)\n",
    "\n",
    "# Very lightweight heuristics for demo purposes\n",
    "tier = \"Highâ€‘Risk (AnnexÂ III â€“ AI in healthcare diagnostics)\"\n",
    "nist_controls = [\"Govern.1 Policy\", \"Map.2 Contextualization\", \"Measure.3 Bias testing\", \"Manage.2 Incident response\"]\n",
    "iso_clauses = [\"4.2 Understanding the organization and its context\",\n",
    "               \"6.1 Actions to address risks and opportunities\",\n",
    "               \"8.2 Operational planning and control\"]\n",
    "\n",
    "print(\"\\nEUÂ AIÂ Act tier â†’\", tier)\n",
    "print(\"\\nNIST AIÂ RMF controls to focus on:\")\n",
    "for c in nist_controls: print(\" â€¢\", c)\n",
    "print(\"\\nISO/IECÂ 42001 clauses:\")\n",
    "for c in iso_clauses: print(\" â€¢\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b84e39",
   "metadata": {},
   "source": [
    "> **Proâ€‘tip**: Replace the heuristic with a call to an LLM:\n",
    "```python\n",
    "import openai, os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "```\n",
    "Then prompt the model to classify the useâ€‘case via the EUÂ AIÂ Act risk taxonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec0658",
   "metadata": {},
   "source": [
    "## ðŸ“„ 3. Parse Official Documents Programmatically  \n",
    "\n",
    "The next cell downloads the NISTÂ AIÂ RMF PDF and extracts the *core functions table* so you can filter or embed it in dashboards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, io, pdfplumber, re, pandas as pd, textwrap, os, pathlib, json, wget, tempfile, bs4, warnings\n",
    "url = \"https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf\"\n",
    "local = \"/mnt/data/ai_rmf.pdf\"\n",
    "if not pathlib.Path(local).exists():\n",
    "    wget.download(url, local)\n",
    "\n",
    "rows = []\n",
    "with pdfplumber.open(local) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        txt = page.extract_text()\n",
    "        if \"Govern\" in txt and \"Manage\" in txt and \"Core Function\" in txt:\n",
    "            for line in txt.splitlines():\n",
    "                m = re.match(r\"(Govern|Map|Measure|Manage)\\s+(.*)\", line)\n",
    "                if m:\n",
    "                    rows.append({\"Function\":m.group(1), \"Description\":m.group(2)})\n",
    "df = pd.DataFrame(rows).drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c435e8",
   "metadata": {},
   "source": [
    "## ðŸ“‘ 4. Generate a Mini *System Card*  \n",
    "\n",
    "System / model cards document capabilities, limitations & mitigations.  \n",
    "Fill the template with an LLM for your own model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template, StrictUndefined\n",
    "template = Template(\"\"\"## System Card â€“ {{ model_name }}\n",
    "\n",
    "### 1. Intended Use\n",
    "{{ intended_use }}\n",
    "\n",
    "### 2. Capabilities\n",
    "{{ capabilities }}\n",
    "\n",
    "### 3. Limitations & Known Issues\n",
    "{{ limitations }}\n",
    "\n",
    "### 4. Safety Evaluations Performed\n",
    "{{ evals }}\n",
    "\n",
    "### 5. Alignment & Mitigations\n",
    "{{ mitigations }}\n",
    "\n",
    "### 6. Update & Contact\n",
    "Last updated: {{ today }}.\n",
    "Contact: {{ contact }}\n",
    "\"\"\", undefined=StrictUndefined)\n",
    "\n",
    "card = template.render(\n",
    "    model_name=\"Studentâ€‘Demo LLaMAâ€‘7B\",\n",
    "    intended_use=\"Educational Q&A for software engineers.\",\n",
    "    capabilities=\"- Programming help\n",
    "- Explanation of CS concepts\",\n",
    "    limitations=\"- May hallucinate stack traces\n",
    "- Limited knowledge after 2025â€‘03\",\n",
    "    evals=\"- TruthfulQA (@62â€¯%)\n",
    "- Bias & toxicity evaluated with LMHarness.\",\n",
    "    mitigations=\"- Prompt isolation\n",
    "- Output filtering via ReACT validation\",\n",
    "    today=str(today),\n",
    "    contact=\"govâ€‘officer@example.com\"\n",
    ")\n",
    "\n",
    "print(card)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a13fe0",
   "metadata": {},
   "source": [
    "## ðŸ“° 5. Governance News Watcher  \n",
    "\n",
    "Use the snippet below to pull the latest 5 news posts tagged *AI Act* from Reuters RSS for classroom discussion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf512ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser, datetime, pytz\n",
    "feed = feedparser.parse(\"https://feeds.reuters.com/reuters/technologyNews\")\n",
    "count = 0\n",
    "for entry in feed.entries:\n",
    "    if \"AI Act\" in entry.title and count < 5:\n",
    "        print(entry.published, \"-\", entry.title)\n",
    "        print(entry.link, \"\\n\")\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6117a",
   "metadata": {},
   "source": [
    "## ðŸ’¬ 6. Discussion & Reflection  \n",
    "\n",
    "1. **Compliance vs. Innovation:** How can startâ€‘ups comply without stifling creativity?  \n",
    "2. **Global Fragmentation:** What risks arise from divergent regional rules?  \n",
    "3. **Enforcement:** Which agencies possess the expertise to audit frontier models?  \n",
    "4. **Openâ€‘Source Models:** Should open weights be treated differently from proprietary APIs?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bdea8",
   "metadata": {},
   "source": [
    "## ðŸ“š Further Reading  \n",
    "\n",
    "* EUÂ AIÂ Act highâ€‘level summary â€“ artificialintelligenceact.eu  \n",
    "* NIST AIÂ RMFÂ 1.0 full PDF â€“ nvlpubs.nist.gov/nistpubs/ai/nist.ai.100â€‘1.pdf  \n",
    "* ISO/IECÂ 42001 overview â€“ iso.org/standard/42001  \n",
    "* WhiteÂ House EOÂ 14110 and OMBÂ Mâ€‘24â€‘10 memo  \n",
    "* International AI Safety ReportÂ 2025 â€“ GOV.UK  \n",
    "* OpenAI GPTâ€‘4o System Card  \n",
    "\n",
    "---\n",
    "\n",
    "Â©Â 2025 Prompt Engineering Class Materials â€“ CCâ€‘BYâ€‘SA\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
