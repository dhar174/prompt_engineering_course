{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c6cb03",
   "metadata": {},
   "source": [
    "# AI & LLM Governance Primer  \n",
    "**Comprehensive Reference & Lab Notebook**  \n",
    "*Last updated: 2025-07-09*  \n",
    "\n",
    "---\n",
    "\n",
    "This Colab notebook is a **deep‑dive resource** covering the **policies, standards, and practical tooling** that currently shape responsible AI and large‑language‑model (LLM) deployment (2025).\n",
    "\n",
    "It blends:\n",
    "\n",
    "* **Curated background reading** (with links & citations)\n",
    "* **Hands‑on code cells**: checklists, PDF parsing, compliance templates, automated policy lookups\n",
    "* **Interactive exercises** so learners can apply governance concepts to their own AI projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04068af7",
   "metadata": {},
   "source": [
    "## 🎯 Learning Objectives\n",
    "By the end, you should be able to:\n",
    "\n",
    "1. **Describe** major AI governance instruments (EU AI Act, NIST AI RMF, ISO 42001, U.S. Executive orders, UK AI Safety Institute, OECD & UNESCO principles).  \n",
    "2. **Map** LLM use‑cases to risk tiers and compliance obligations.  \n",
    "3. **Generate** a lightweight *System Card* and *Model Card* using structured prompts.  \n",
    "4. **Automate** governance tasks: parse policy PDFs, track regulatory updates, run checklists.  \n",
    "5. **Critically discuss** gaps, emerging trends, and open questions in frontier model oversight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150339b",
   "metadata": {},
   "source": [
    "## 🌍 1. Global Policy Landscape (2024‑2025)\n",
    "\n",
    "| Region / Org | Instrument | Status | Key Features |\n",
    "|--------------|------------|--------|--------------|\n",
    "| **EU** | **AI Act** (Regulation (EU) 2024/1112) | Final text adopted 2024; enforcement starts Aug 2025 (phased) | Risk‑based tiers (unacceptable ⇢ minimal), GPAI obligations, transparency, fundamental‑rights impact assessment |\n",
    "| **USA (Federal)** | **Executive Order 14110** (Safe, Secure & Trustworthy AI) + **OMB M‑24‑10** memorandum | In force (2023‑2024) | Agency risk management, red‑team sharing, NIST testing, watermarking R&D |\n",
    "| **USA (NIST)** | **AI Risk Management Framework 1.0** | Voluntary (Jan 2023) | *Govern – Map – Measure – Manage* core functions; profiles & playbooks |\n",
    "| **ISO/IEC** | **42001:2023 AIMS** | Published Dec 2023 | Management‑system standard akin to ISO 27001 but for AI governance |\n",
    "| **UK** | **AI Safety Institute** evaluations + *International AI Safety Report 2025* | Ongoing | Frontier‑model testing protocols, red‑team hubs |\n",
    "| **OECD / UNESCO** | **OECD AI Principles (2019)**, **UNESCO Recommendation (2021)** | Soft law | Human‑centered, accountability, transparency, sustainable society |\n",
    "\n",
    "> 📌 **Why multiple layers?** Regulations set *obligations*, standards provide *how*, frameworks guide *process*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696f4e0",
   "metadata": {},
   "source": [
    "## 🔎 2. Map‑Your‑Use‑Case to Risk Tiers  \n",
    "\n",
    "Run the cell below to input a short description of an AI application and receive:\n",
    "\n",
    "* EU AI Act tier suggestion  \n",
    "* Recommended NIST AI RMF controls  \n",
    "* Flagged ISO 42001 clauses  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7394823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, textwrap\n",
    "description = \"Chatbot doctor that gives medical diagnosis to patients online\"\n",
    "print(\"Use‑case:\", description)\n",
    "\n",
    "# Very lightweight heuristics for demo purposes\n",
    "tier = \"High‑Risk (Annex III – AI in healthcare diagnostics)\"\n",
    "nist_controls = [\"Govern.1 Policy\", \"Map.2 Contextualization\", \"Measure.3 Bias testing\", \"Manage.2 Incident response\"]\n",
    "iso_clauses = [\"4.2 Understanding the organization and its context\",\n",
    "               \"6.1 Actions to address risks and opportunities\",\n",
    "               \"8.2 Operational planning and control\"]\n",
    "\n",
    "print(\"\\nEU AI Act tier →\", tier)\n",
    "print(\"\\nNIST AI RMF controls to focus on:\")\n",
    "for c in nist_controls: print(\" •\", c)\n",
    "print(\"\\nISO/IEC 42001 clauses:\")\n",
    "for c in iso_clauses: print(\" •\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b84e39",
   "metadata": {},
   "source": [
    "> **Pro‑tip**: Replace the heuristic with a call to an LLM:\n",
    "```python\n",
    "import openai, os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "```\n",
    "Then prompt the model to classify the use‑case via the EU AI Act risk taxonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec0658",
   "metadata": {},
   "source": [
    "## 📄 3. Parse Official Documents Programmatically  \n",
    "\n",
    "The next cell downloads the NIST AI RMF PDF and extracts the *core functions table* so you can filter or embed it in dashboards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, io, pdfplumber, re, pandas as pd, textwrap, os, pathlib, json, wget, tempfile, bs4, warnings\n",
    "url = \"https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf\"\n",
    "local = \"/mnt/data/ai_rmf.pdf\"\n",
    "if not pathlib.Path(local).exists():\n",
    "    wget.download(url, local)\n",
    "\n",
    "rows = []\n",
    "with pdfplumber.open(local) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        txt = page.extract_text()\n",
    "        if \"Govern\" in txt and \"Manage\" in txt and \"Core Function\" in txt:\n",
    "            for line in txt.splitlines():\n",
    "                m = re.match(r\"(Govern|Map|Measure|Manage)\\s+(.*)\", line)\n",
    "                if m:\n",
    "                    rows.append({\"Function\":m.group(1), \"Description\":m.group(2)})\n",
    "df = pd.DataFrame(rows).drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c435e8",
   "metadata": {},
   "source": [
    "## 📑 4. Generate a Mini *System Card*  \n",
    "\n",
    "System / model cards document capabilities, limitations & mitigations.  \n",
    "Fill the template with an LLM for your own model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2404534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template, StrictUndefined\n",
    "template = Template(\"\"\"## System Card – {{ model_name }}\n",
    "\n",
    "### 1. Intended Use\n",
    "{{ intended_use }}\n",
    "\n",
    "### 2. Capabilities\n",
    "{{ capabilities }}\n",
    "\n",
    "### 3. Limitations & Known Issues\n",
    "{{ limitations }}\n",
    "\n",
    "### 4. Safety Evaluations Performed\n",
    "{{ evals }}\n",
    "\n",
    "### 5. Alignment & Mitigations\n",
    "{{ mitigations }}\n",
    "\n",
    "### 6. Update & Contact\n",
    "Last updated: {{ today }}.\n",
    "Contact: {{ contact }}\n",
    "\"\"\", undefined=StrictUndefined)\n",
    "\n",
    "card = template.render(\n",
    "    model_name=\"Student‑Demo LLaMA‑7B\",\n",
    "    intended_use=\"Educational Q&A for software engineers.\",\n",
    "    capabilities=\"- Programming help\n",
    "- Explanation of CS concepts\",\n",
    "    limitations=\"- May hallucinate stack traces\n",
    "- Limited knowledge after 2025‑03\",\n",
    "    evals=\"- TruthfulQA (@62 %)\n",
    "- Bias & toxicity evaluated with LMHarness.\",\n",
    "    mitigations=\"- Prompt isolation\n",
    "- Output filtering via ReACT validation\",\n",
    "    today=str(today),\n",
    "    contact=\"gov‑officer@example.com\"\n",
    ")\n",
    "\n",
    "print(card)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a13fe0",
   "metadata": {},
   "source": [
    "## 📰 5. Governance News Watcher  \n",
    "\n",
    "Use the snippet below to pull the latest 5 news posts tagged *AI Act* from Reuters RSS for classroom discussion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf512ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser, datetime, pytz\n",
    "feed = feedparser.parse(\"https://feeds.reuters.com/reuters/technologyNews\")\n",
    "count = 0\n",
    "for entry in feed.entries:\n",
    "    if \"AI Act\" in entry.title and count < 5:\n",
    "        print(entry.published, \"-\", entry.title)\n",
    "        print(entry.link, \"\\n\")\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6117a",
   "metadata": {},
   "source": [
    "## 💬 6. Discussion & Reflection  \n",
    "\n",
    "1. **Compliance vs. Innovation:** How can start‑ups comply without stifling creativity?  \n",
    "2. **Global Fragmentation:** What risks arise from divergent regional rules?  \n",
    "3. **Enforcement:** Which agencies possess the expertise to audit frontier models?  \n",
    "4. **Open‑Source Models:** Should open weights be treated differently from proprietary APIs?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bdea8",
   "metadata": {},
   "source": [
    "## 📚 Further Reading  \n",
    "\n",
    "* EU AI Act high‑level summary – artificialintelligenceact.eu  \n",
    "* NIST AI RMF 1.0 full PDF – nvlpubs.nist.gov/nistpubs/ai/nist.ai.100‑1.pdf  \n",
    "* ISO/IEC 42001 overview – iso.org/standard/42001  \n",
    "* White House EO 14110 and OMB M‑24‑10 memo  \n",
    "* International AI Safety Report 2025 – GOV.UK  \n",
    "* OpenAI GPT‑4o System Card  \n",
    "\n",
    "---\n",
    "\n",
    "© 2025 Prompt Engineering Class Materials – CC‑BY‑SA\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
