{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be50876",
   "metadata": {},
   "source": [
    "# üß©‚ú® Extra Tree‚Äë/Graph‚Äëof‚ÄëThought Puzzles + LLM‚ÄëScoring Examples\n",
    "\n",
    "*Supplementary Lab ‚Äì Day¬†5*\n",
    "\n",
    "Explore **three** additional classic puzzles with both heuristic *and* **LLM‚Äëdriven** scoring options:\n",
    "\n",
    "1. **Eight‚ÄëPuzzle** (3√ó3 sliding tiles)  \n",
    "2. **Tower of Hanoi** (minimal-move search)  \n",
    "3. **Word Ladder** (single‚Äëletter transformations)  \n",
    "\n",
    "Each demo is implemented with a generic `TreeOfThoughtSolver` (beam search) and shows how to plug in OpenAI scoring so the language model evaluates partial states.\n",
    "\n",
    "> üí°¬†Set the `OPENAI_API_KEY` environment variable for LLM scoring, or run heuristic‚Äëonly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497882c",
   "metadata": {},
   "source": [
    "## üîß 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install --upgrade openai networkx matplotlib\n",
    "import os, random, copy, math, itertools, collections\n",
    "import openai, networkx as nx, matplotlib.pyplot as plt\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # optional\n",
    "MODEL = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2e0ec",
   "metadata": {},
   "source": [
    "### Generic ToT Beam Solver (reuse)\n",
    "\n",
    "Same as earlier notebook ‚Äì beam search with pluggable `expand_fn` & `score_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ad674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTSolver:\n",
    "    def __init__(self, expand_fn, score_fn, beam=5, max_depth=30, verbose=False):\n",
    "        self.expand=expand_fn; self.score=score_fn\n",
    "        self.beam=beam; self.max_depth=max_depth; self.verbose=verbose\n",
    "    def solve(self, init_state, goal_test):\n",
    "        frontier=[(init_state, self.score(init_state))]\n",
    "        for depth in range(self.max_depth):\n",
    "            if self.verbose:\n",
    "                print(f\"Depth {depth}: frontier {len(frontier)}\")\n",
    "            new=[]\n",
    "            for state, _ in frontier:\n",
    "                if goal_test(state):\n",
    "                    return state\n",
    "                for child in self.expand(state):\n",
    "                    new.append((child, self.score(child)))\n",
    "            frontier=sorted(new, key=lambda x:-x[1])[:self.beam]\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14368846",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Eight‚ÄëPuzzle (Sliding Tiles)\n",
    "\n",
    "**State**: tuple of 9 ints, 0 = blank  \n",
    "**Expand**: slide blank up/down/left/right  \n",
    "**Heuristic Score**: Negative Manhattan distance to goal.  \n",
    "**LLM Score** (optional): Ask the model to rate closeness to goal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOAL=(1,2,3,4,5,6,7,8,0)\n",
    "\n",
    "def pos(idx): return divmod(idx,3)\n",
    "\n",
    "moves=[(-1,0),(1,0),(0,-1),(0,1)]\n",
    "def expand_8p(state):\n",
    "    idx=state.index(0)\n",
    "    r,c=pos(idx)\n",
    "    children=[]\n",
    "    for dr,dc in moves:\n",
    "        nr,nc=r+dr,c+dc\n",
    "        if 0<=nr<3 and 0<=nc<3:\n",
    "            nidx=nr*3+nc\n",
    "            lst=list(state)\n",
    "            lst[idx],lst[nidx]=lst[nidx],lst[idx]\n",
    "            children.append(tuple(lst))\n",
    "    return children\n",
    "\n",
    "def manhattan(state):\n",
    "    dist=0\n",
    "    for i,val in enumerate(state):\n",
    "        if val==0: continue\n",
    "        goal_r,goal_c=pos(val-1)\n",
    "        cur_r,cur_c=pos(i)\n",
    "        dist+=abs(goal_r-cur_r)+abs(goal_c-cur_c)\n",
    "    return -dist\n",
    "\n",
    "def llm_score_8p(state):\n",
    "    if not openai.api_key: return manhattan(state)\n",
    "    prompt=f\"Eight‚ÄëPuzzle board {state}. Rate on a scale -30 (far) to 0 (goal) how close this board is to solved (1 2 3 / 4 5 6 / 7 8 _). Return a single integer.\"\n",
    "    try:\n",
    "        resp=openai.ChatCompletion.create(model=MODEL,messages=[{\"role\":\"user\",\"content\":prompt}],temperature=0)\n",
    "        return int(resp.choices[0].message.content.strip())\n",
    "    except:\n",
    "        return manhattan(state)\n",
    "\n",
    "start=(1,2,3,4,5,6,0,7,8)\n",
    "print(\"Start\",start)\n",
    "solver8=ToTSolver(expand_8p,llm_score_8p,beam=10,max_depth=30)\n",
    "solution=solver8.solve(start, lambda s:s==GOAL)\n",
    "print(\"Solved?\", solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fabc0",
   "metadata": {},
   "source": [
    "#### üìù Try‚Äëit\n",
    "\n",
    "* Shuffle `start` with more complex permutations.  \n",
    "* Compare `manhattan` vs. `llm_score_8p`.  \n",
    "* Does the LLM score ever outperform heuristics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2cb5ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Tower of Hanoi (3 rods)\n",
    "\n",
    "Goal: move entire stack from rod¬†A to rod¬†C following rules.\n",
    "\n",
    "We demonstrate ToT beam search with **LLM pruning**: model rates partial states on ‚Äústeps away from goal.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99da871",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM=4  # discs\n",
    "GOAL=((),(),tuple(range(NUM,0,-1)))\n",
    "\n",
    "def expand_hanoi(state):\n",
    "    rods=[list(r) for r in state]\n",
    "    children=[]\n",
    "    for i in range(3):\n",
    "        if not rods[i]: continue\n",
    "        disc=rods[i][-1]\n",
    "        for j in range(3):\n",
    "            if i==j: continue\n",
    "            if rods[j] and rods[j][-1]<disc: continue\n",
    "            new_rods=[list(r) for r in rods]\n",
    "            new_rods[i].pop()\n",
    "            new_rods[j].append(disc)\n",
    "            children.append(tuple(tuple(r) for r in new_rods))\n",
    "    return children\n",
    "\n",
    "def heuristic_h(state):\n",
    "    return -sum(len(r)*(idx!=2) for idx,r in enumerate(state))  # more on rod C = better\n",
    "\n",
    "def llm_score_h(state):\n",
    "    if not openai.api_key: return heuristic_h(state)\n",
    "    prompt=f\"Tower of Hanoi state {state}. How close is this to all discs on rod C (goal)? Reply an integer from -20 (far) to 0 (goal).\" \n",
    "    try:\n",
    "        out=openai.ChatCompletion.create(model=MODEL,messages=[{\"role\":\"user\",\"content\":prompt}],temperature=0)\n",
    "        return int(out.choices[0].message.content.strip())\n",
    "    except:\n",
    "        return heuristic_h(state)\n",
    "\n",
    "init=(tuple(range(NUM,0,-1)),(),())\n",
    "solverH=ToTSolver(expand_hanoi,llm_score_h,beam=15,max_depth=40)\n",
    "sol=solverH.solve(init, lambda s:s==GOAL)\n",
    "print(\"Success:\", sol==GOAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b02d37",
   "metadata": {},
   "source": [
    "#### üìù Challenge\n",
    "\n",
    "* Raise `NUM` to 5 or 6 discs. Beam search blows up ‚Äì can LLM scores guide search better?  \n",
    "* Compare required depth vs. theoretical minimum (2^n‚Äë1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b85163",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Word Ladder (LLM‚Äëscored)\n",
    "\n",
    "Transform *start* ‚ûú *end* by changing **one letter** at a time, each intermediate must be an English word.\n",
    "\n",
    "LLM helps score partial ladders by evaluating semantic closeness or plausibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, string\n",
    "wordlist=[w.strip() for w in requests.get('https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt').text.splitlines() if len(w)==5]\n",
    "DICT=set(wordlist)\n",
    "\n",
    "def neighbors(word):\n",
    "    out=[]\n",
    "    for i,ch in enumerate(word):\n",
    "        for l in string.ascii_lowercase:\n",
    "            if l==ch: continue\n",
    "            new=word[:i]+l+word[i+1:]\n",
    "            if new in DICT:\n",
    "                out.append(new)\n",
    "    return out\n",
    "\n",
    "def expand_ladder(state):\n",
    "    path=state\n",
    "    last=path[-1]\n",
    "    return [path+[n] for n in neighbors(last) if n not in path]\n",
    "\n",
    "target=\"crown\"; start=\"stone\"\n",
    "\n",
    "def heuristic_ladder(path):\n",
    "    last=path[-1]\n",
    "    matches=sum(a==b for a,b in zip(last,target))\n",
    "    return matches\n",
    "\n",
    "def llm_score_ladder(path):\n",
    "    if not openai.api_key: return heuristic_ladder(path)\n",
    "    prompt=f\"We are playing Word Ladder. Current path: {path}. Target word: '{target}'. Rate how promising this path is (0‚Äë5, 5=almost there). Return a number.\"\n",
    "    try:\n",
    "        r=openai.ChatCompletion.create(model=MODEL,messages=[{\"role\":\"user\",\"content\":prompt}],temperature=0)\n",
    "        return float(r.choices[0].message.content.strip())\n",
    "    except:\n",
    "        return heuristic_ladder(path)\n",
    "\n",
    "solverW=ToTSolver(expand_ladder,llm_score_ladder,beam=25,max_depth=10)\n",
    "solution=solverW.solve([start], lambda p:p[-1]==target)\n",
    "print(\"Solution path:\", solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d1437",
   "metadata": {},
   "source": [
    "#### üìù Experiments\n",
    "\n",
    "* Change `start`/`target` pair.  \n",
    "* Observe how LLM scoring differs from naive letter‚Äëmatch heuristic ‚Äì does it favor meaningful intermediates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b2363b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîó References & Ideas\n",
    "\n",
    "* Silver et¬†al., ‚ÄúMastering the Game of Go with Deep Neural Networks and Tree Search‚Äù, 2016 ‚Äì classic example of MCTS  \n",
    "* Yao et¬†al., 2023 ‚Äì ToT with game & math puzzles  \n",
    "* Long¬†&¬†Bosch, 2024 ‚Äì Graph‚Äëof‚ÄëThought memory graphs\n",
    "\n",
    "Happy puzzling!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
