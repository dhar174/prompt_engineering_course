{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a21cb69",
   "metadata": {},
   "source": [
    "# Prompt Engineering Notebook: Retrieval‑Augmented Generation (RAG)\n",
    "*Google Colab–Compatible — Author: ChatGPT (o3) — Date: 2025-07-09*\n",
    "\n",
    "This interactive notebook demystifies **Retrieval‑Augmented Generation**—injecting external knowledge into language‑model prompts at runtime to boost accuracy, reduce hallucination, and keep responses fresh.\n",
    "\n",
    "> 🧑‍🏫 *Pedagogical design note:* Each section follows the **explain‑demo‑exercise** pattern, with progressively richer challenges and built‑in reflection checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23fd12",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "By the end of this notebook you will be able to:\n",
    "1. Explain the standard RAG pipeline and why it mitigates hallucinations.\n",
    "2. Build a toy document store with embeddings + FAISS and perform similarity search.\n",
    "3. Craft dynamic prompts that combine retrieved context with user questions.\n",
    "4. Evaluate RAG responses for relevance and factual grounding using simple metrics.\n",
    "5. Experiment with chunking, hybrid search, and citation formatting.\n",
    "6. Identify safety & bias pitfalls unique to RAG systems and propose mitigations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46138c4",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "Run the next cell to install lightweight dependencies. Feel free to comment‑out packages you already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9330a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain openai faiss-cpu python-dotenv tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec9eff",
   "metadata": {},
   "source": [
    "### Configure API Credentials\n",
    "Enter your OpenAI API key below (optional—offline demo stubs will be used if absent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    os.environ['OPENAI_API_KEY'] = getpass.getpass('🔑 OpenAI API Key (optional): ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59936aba",
   "metadata": {},
   "source": [
    "## 1. Why Retrieval‑Augmented Generation?\n",
    "Large language models (LLMs) possess vast latent knowledge but **forget specifics** and **freeze in time**. RAG connects them to an up‑to‑date knowledge base **at inference‑time**:\n",
    "```text\n",
    "User Query ─▶ Retriever ─▶ Relevant Chunks ─┐\n",
    "                                   ⬇         │\n",
    "                       [Prompt Template]      │\n",
    "                                   ⬇         │\n",
    "                                  LLM ────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551da56f",
   "metadata": {},
   "source": [
    "### Key Benefits\n",
    "1. **Freshness 📅** – Inject new documents without retraining.\n",
    "2. **Explainability 🔍** – Provide citations for retrieved passages.\n",
    "3. **Efficiency ⚡** – Smaller models can perform expert tasks when paired with domain docs.\n",
    "4. **Control 🛠️** – Curate the knowledge corpus to steer model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a437f19",
   "metadata": {},
   "source": [
    "## 2. Hands‑On Part I – Create a Toy Document Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "sample_docs = {\n",
    "    \"transformers\": \"\"\"Transformers are neural network architectures that rely on self‑attention. \n",
    "They have become the backbone of modern NLP.\"\"\",\n",
    "    \"vector-db\": \"\"\"FAISS is a library for efficient similarity search and clustering of dense vectors.\"\"\",\n",
    "    \"rag\": \"\"\"Retrieval‑Augmented Generation pipelines retrieve relevant chunks from external documents \n",
    "and feed them into the prompt of an LLM.\"\"\"\n",
    "}\n",
    "\n",
    "# Split into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=80, chunk_overlap=10)\n",
    "docs = []\n",
    "for title, text in sample_docs.items():\n",
    "    for chunk in splitter.split_text(text):\n",
    "        docs.append(chunk)\n",
    "print(f\"📄 {len(docs)} chunks created:\")\n",
    "for d in docs:\n",
    "    print('-', d[:60] + ('...' if len(d) > 60 else ''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e43a80",
   "metadata": {},
   "source": [
    "### 2.1 Embed & Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    from langchain.embeddings import OpenAIEmbeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "else:\n",
    "    # Offline stub embeds by hashing\n",
    "    import numpy as np, hashlib\n",
    "    class HashEmbeddings:\n",
    "        def embed_documents(self, texts):\n",
    "            return [np.array([int(hashlib.md5(t.encode()).hexdigest(),16)%997]) for t in texts]\n",
    "    embeddings = HashEmbeddings()\n",
    "\n",
    "db = FAISS.from_texts(docs, embeddings)\n",
    "print('✅ Vector store ready —', db.index.ntotal, 'vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5b076",
   "metadata": {},
   "source": [
    "### 2.2 Similarity Search Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What library helps with similarity search for embeddings?\"\n",
    "docs_ret = db.similarity_search(query, k=2)\n",
    "for i,d in enumerate(docs_ret,1):\n",
    "    print(f\"Doc {i} ▶\", d.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bacb8f8",
   "metadata": {},
   "source": [
    "**Exercise 📝**: Change `query` and re‑run. Observe retrieved snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b55709",
   "metadata": {},
   "source": [
    "## 3. Hands‑On Part II – Plug Retrieval into Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ae680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(question, contexts):\n",
    "    joined = \"\\n---\\n\".join(contexts)\n",
    "    return f\"\"\"Answer the question using the context below. Cite sources using [doc #].\n",
    "\n",
    "Context:\n",
    "{joined}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "def ask_rag(question, k=3):\n",
    "    ctx = [d.page_content for d in db.similarity_search(question, k=k)]\n",
    "    prompt = format_prompt(question, ctx)\n",
    "    if os.getenv('OPENAI_API_KEY'):\n",
    "        from langchain.llms import OpenAI\n",
    "        llm = OpenAI(temperature=0)\n",
    "        return llm(prompt)\n",
    "    else:\n",
    "        # Offline stub: echo context keywords\n",
    "        return \"Stub‑LLM answer based on retrieved info: \" + ', '.join(ctx)\n",
    "\n",
    "print(ask_rag(\"Explain what FAISS does.\", k=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b637b",
   "metadata": {},
   "source": [
    "**Checkpoint 🔎**: Does the answer cite sources? If not, tweak `format_prompt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e764cf0c",
   "metadata": {},
   "source": [
    "## 4. Experiment – Chunk Size vs. Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0261c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, numpy as np\n",
    "\n",
    "sizes = [32, 64, 128, 256]\n",
    "recall_scores=[]\n",
    "for cs in sizes:\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=cs, chunk_overlap=10)\n",
    "    chunks = sum(len(splitter.split_text(t)) for t in sample_docs.values())\n",
    "    recall_scores.append(min(1, 80/cs))  # fake metric for demo\n",
    "\n",
    "plt.plot(sizes, recall_scores, marker='o')\n",
    "plt.title(\"Effect of Chunk Size on (Toy) Recall\")\n",
    "plt.xlabel(\"Chunk Size (chars)\")\n",
    "plt.ylabel(\"Recall (proxy)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e6bf5",
   "metadata": {},
   "source": [
    "> **Reflection 💡**: Larger chunks capture more context but may dilute retrieval precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e4554",
   "metadata": {},
   "source": [
    "## 5. Evaluating RAG Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b0885",
   "metadata": {},
   "source": [
    "*Automatic heuristics*\n",
    "- **Context precision**: % of retrieved chunks actually used in answer.\n",
    "- **Citation accuracy**: Do cited docs support the claim?\n",
    "- **Answer faithfulness**: Compare with ground truth via LLM verifier or overlap metrics.\n",
    "\n",
    "*Manual checklist*\n",
    "- Factual correctness?\n",
    "- Is necessary info missing?\n",
    "- Tone & completeness?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b02c3f",
   "metadata": {},
   "source": [
    "## 6. Going Further\n",
    "- **Hybrid retrieval**: combine dense (embeddings) + sparse (BM25) search.\n",
    "- **Graph‑based retrieval**: store doc relationships and traverse paths.\n",
    "- **Multi‑hop RAG**: iterative retrieval to answer complex queries.\n",
    "- **Streaming RAG**: produce partial answers while fetching more chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c838b",
   "metadata": {},
   "source": [
    "## 7. Safety & Bias Considerations\n",
    "- **Data poisoning**: Malicious docs may steer outputs → Validate sources.\n",
    "- **Privacy leaks**: Retrieved chunks might expose sensitive info → Access control.\n",
    "- **Confabulations**: LLM may still hallucinate even with context → Force citation and compare.\n",
    "- **License compliance**: Ensure you have rights to redistribute retrieved content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33ba38",
   "metadata": {},
   "source": [
    "## Assignment 📚\n",
    "1. Build a mini‑knowledge base from **any 3 Wikipedia articles** of your choice.\n",
    "2. Implement a RAG function that answers *five* trivia questions about those topics.\n",
    "3. Report precision, citation accuracy, and one failure case with analysis.\n",
    "4. *(Stretch)* Swap FAISS for **Chroma** or **Weaviate** and compare retrieval latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a7dd1",
   "metadata": {},
   "source": [
    "## Further Reading & Tools\n",
    "- Lewis et al., *Retrieval‑Augmented Generation for Knowledge‑Intensive NLP* (2020)\n",
    "- LlamaIndex (GPT Index) and LangChain RAG templates\n",
    "- **Haystack** framework (deepset) for production RAG pipelines\n",
    "- OpenAI Cookbook: *Evaluating RAG pipelines*\n",
    "- Papers with Code: <https://paperswithcode.com/task/retrieval-augmented-generation>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
