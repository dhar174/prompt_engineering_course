{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b3aa15",
   "metadata": {},
   "source": [
    "# Shot\u2011Prompt Patterns Playground  \n",
    "Explore **zero\u2011shot**, **one\u2011shot**, and **few\u2011shot** prompting in a single interface.\n",
    "\n",
    "**Objective:**  \n",
    "See how adding examples (shots) in the prompt changes an LLM\u2019s output accuracy, tone, and depth.  \n",
    "Works in Colab or any local Jupyter (just set `OPENAI_API_KEY`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patterns",
   "metadata": {},
   "source": [
    "### Prompting Patterns & Delimiters\n",
    "- Use `System`, `User`, and `Assistant` roles where possible.\n",
    "- Wrap long text or code in triple backticks ``` for clarity.\n",
    "- Separate examples with `input \u21a2 output` so they parse cleanly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "examplesets",
   "metadata": {},
   "source": [
    "### Building Small Example Sets\n",
    "1. Start with a couple of typical input/output pairs.\n",
    "2. Add one edge case or tricky example.\n",
    "3. Keep them short\u2014just enough context to steer the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb718f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install openai ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai, json, ipywidgets as w\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ðŸ”‘  Enter your key (or leave blank if calling a local model wrapper)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'sk-')\n",
    "\n",
    "task_box = w.Textarea(\n",
    "    value='Translate to French:',\n",
    "    placeholder='Describe your task here\u2026',\n",
    "    description='Task:',\n",
    "    layout=w.Layout(width='100%', height='60px'))\n",
    "\n",
    "shots_dropdown = w.Dropdown(\n",
    "    options=[('0 - Zero',0), ('1 - One',1), ('3 - Few',3)],\n",
    "    value=0,\n",
    "    description='Examples:')\n",
    "\n",
    "examples_box = w.Textarea(\n",
    "    value='Example EN: Hello\n",
    "Example FR: Bonjour',\n",
    "    placeholder='Provide k example pairs separated by newline\n",
    "Format: input \u21a2 output',\n",
    "    description='Examples:',\n",
    "    layout=w.Layout(width='100%', height='120px'))\n",
    "\n",
    "temperature_slider = w.FloatSlider(value=0.7, min=0, max=1.5, step=0.1,\n",
    "                                   description='Temperature')\n",
    "\n",
    "run_btn = w.Button(description='Run \ud83d\udd90')\n",
    "out = w.Output()\n",
    "\n",
    "def build_messages():\n",
    "    k = int(shots_dropdown.value)\n",
    "    messages = [{'role':'user','content': task_box.value}]\n",
    "    if k > 0:\n",
    "        lines = [l.strip() for l in examples_box.value.splitlines() if l.strip()]\n",
    "        pair_lines = lines[:k]  # grab first k example lines\n",
    "        for ln in pair_lines:\n",
    "            if '\u21a2' in ln:\n",
    "                src, tgt = ln.split('\u21a2', 1)\n",
    "            elif ':' in ln:\n",
    "                src, tgt = ln.split(':', 1)\n",
    "            else:\n",
    "                continue\n",
    "            messages.append({'role':'user','content': src.strip()})\n",
    "            messages.append({'role':'assistant','content': tgt.strip()})\n",
    "    # final user prompt again\n",
    "    messages.append({'role':'user','content': task_box.value})\n",
    "    return messages\n",
    "\n",
    "def run(b):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        messages = build_messages()\n",
    "        print('Prompt messages:', json.dumps(messages, indent=2))\n",
    "        try:\n",
    "            resp = openai.ChatCompletion.create(\n",
    "                model='gpt-4o-mini',\n",
    "                messages=messages,\n",
    "                temperature=temperature_slider.value,\n",
    "                max_tokens=256\n",
    "            )\n",
    "            display(Markdown('### \u2728\u00a0Model Response\n",
    "' + resp.choices[0].message.content))\n",
    "        except Exception as e:\n",
    "            print('Error:', e)\n",
    "\n",
    "run_btn.on_click(run)\n",
    "\n",
    "ui = w.VBox([task_box, shots_dropdown, examples_box,\n",
    "             temperature_slider, run_btn, out])\n",
    "display(ui)\n",
    "print('Adjust *Examples* and supply sample pairs to compare outputs.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76762fb4",
   "metadata": {},
   "source": [
    "---  \n",
    "### Suggested Experiments  \n",
    "1. Try `k=0` vs `k=3` on classification tasks.  \n",
    "2. Observe how example **ordering** changes output.  \n",
    "3. Combine with higher temperature for extra creativity."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
